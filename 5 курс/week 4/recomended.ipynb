{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "#### Входные данные\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "#### Важно:\n",
    "\n",
    "- Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "- Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "- Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "- Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n",
    "\n",
    "#### Задание\n",
    "\n",
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    " - сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    " - сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "#### Дополнительные вопросы\n",
    "\n",
    "1. Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров recall@k меняется. Подумайте, как оценить минимальное и максимальное значение recall@k в зависимости от правила сортировки.\n",
    "2. Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9,10,11,9,11,12,9,11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16,17,18,19,20,21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24,25,26,27,24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34,35,36,34,37,35,36,37,38,39,38,39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                viewed bought\n",
       "0                 9,10,11,9,11,12,9,11    NaN\n",
       "1                    16,17,18,19,20,21    NaN\n",
       "2                       24,25,26,27,24    NaN\n",
       "3  34,35,36,34,37,35,36,37,38,39,38,39    NaN\n",
       "4                                   42    NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\n",
    "    \"coursera_sessions_train.txt\",\n",
    "    \";\",\n",
    "    header=0,\n",
    "    names=[\"viewed\", \"bought\"])\n",
    "data_test = pd.read_csv(\n",
    "    \"coursera_sessions_test.txt\",\n",
    "    \";\",\n",
    "    header=0,\n",
    "    names=[\"viewed\", \"bought\"]).dropna(axis=0, how=\"any\")\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_session_column(column):\n",
    "    \"\"\" parses string from session column \"\"\"\n",
    "    return [int(val) for val in column.split(\",\")]\n",
    "\n",
    "\n",
    "def parse_session(views, buys):\n",
    "    \"\"\" parses session string \"\"\"\n",
    "    return (parse_session_column(views),\n",
    "            parse_session_column(buys) if isinstance(buys, str) else [])\n",
    "\n",
    "\n",
    "def update_frequencies_count(keys, frequencies):\n",
    "    \"\"\" increments dictionary value if key is present in dictionary or puts this key \"\"\"\n",
    "    for key in keys:\n",
    "        frequencies[key] = frequencies[key] + 1 if key in frequencies else 1\n",
    "\n",
    "        \n",
    "def build_data_frequencies(data):\n",
    "    \"\"\" counts product frequencies in views and buys \"\"\"\n",
    "    view_freqs = {}\n",
    "    buy_freqs = {}\n",
    "    for views_col, buys_col in data.as_matrix():\n",
    "        views, buys = parse_session(views_col, buys_col)\n",
    "        update_frequencies_count(views, view_freqs)\n",
    "        update_frequencies_count(buys, buy_freqs)\n",
    "    return view_freqs, buy_freqs\n",
    "\n",
    "\n",
    "def merge(left_list, left_length, right_list, right_length, key, descending):\n",
    "    \"\"\" applies ordered merging of two lists based on key \"\"\"\n",
    "    left_index = 0\n",
    "    right_index = 0\n",
    "    result = []\n",
    "    if descending:\n",
    "        less_than = (lambda right, left: right > left)\n",
    "    else:\n",
    "        less_than = (lambda right, left: right < left)\n",
    "    while left_index < left_length and right_index < right_length:\n",
    "        left = left_list[left_index]\n",
    "        right = right_list[right_index]\n",
    "        if less_than(key(right), key(left)):\n",
    "            result.append(right)\n",
    "            right_index += 1\n",
    "        else:\n",
    "            result.append(left)\n",
    "            left_index += 1\n",
    "    if left_index == left_length:\n",
    "        return result + right_list[right_index:right_length]\n",
    "    else:\n",
    "        return result + left_list[left_index:left_length]\n",
    "\n",
    "\n",
    "def merge_sort(data, key, descending=False):\n",
    "    \"\"\" Applies merge sort in data based on key \"\"\"\n",
    "    list_length = len(data)\n",
    "    if list_length > 1:\n",
    "        left_length = int(list_length/2)\n",
    "        right_length = list_length-left_length\n",
    "        left_list = merge_sort(data[0:left_length], key, descending)\n",
    "        right_list = merge_sort(data[left_length:list_length], key, descending)\n",
    "\n",
    "        return merge(left_list, left_length, right_list, right_length, key, descending)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danila/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "view_frequencies, buy_frequencies = build_data_frequencies(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity(view, frequencies):\n",
    "    \"\"\" Calculates item popularity based on frequency value. \"\"\"\n",
    "    return float(frequencies[view] if view in frequencies else 0)\n",
    "\n",
    "def unique_values(data, key):\n",
    "    \"\"\" returns unique items from data based on key value \"\"\"\n",
    "    values = {}\n",
    "    result = []\n",
    "    for value in data:\n",
    "        k = key(value)\n",
    "        if k not in values:\n",
    "            result.append(value)\n",
    "            values[k] = True\n",
    "    return result\n",
    "\n",
    "def build_recommendations(views, frequencies, k):\n",
    "    \"\"\" sort session data based on appearence in frequency dictionary \"\"\"\n",
    "    views_popularity = [(view, popularity(view, frequencies)) for view in views]\n",
    "    sorted_views = merge_sort(views_popularity, lambda v: v[1], descending=True)\n",
    "    views_count = len(set(views))\n",
    "    return [view for (view, pop) in unique_values(sorted_views, lambda v: v[0])][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(buys, recommendations, k):\n",
    "    \"\"\" calculates precision of recommendations \"\"\"\n",
    "    recomended_buys = [1 if recommendation in buys else 0 for recommendation in recommendations]\n",
    "    return float(sum(recomended_buys))/float(k)\n",
    "\n",
    "def recall(buys, recommendations):\n",
    "    \"\"\" calculates recall of recommendations \"\"\"\n",
    "    recomended_buys = [1 if recommendation in buys else 0 for recommendation in recommendations]\n",
    "    return float(sum(recomended_buys))/float(len(buys)) if len(recomended_buys) > 0 else 0.\n",
    "\n",
    "def estimate_model(data, model, k):\n",
    "    \"\"\" estimates recommendations provided by model based on precision and recall \"\"\"\n",
    "    precision_sum = 0.\n",
    "    recall_sum = 0.\n",
    "    for views_col, buys_col in data.as_matrix():\n",
    "        views, buys = parse_session(views_col, buys_col)\n",
    "        recommendations = model(views, k)\n",
    "        precision_sum += precision(buys, recommendations, k)\n",
    "        recall_sum += recall(buys, recommendations)\n",
    "    data_length = float(len(data))\n",
    "    return (recall_sum/data_length, precision_sum/data_length)\n",
    "\n",
    "def save_answer_array(fname, array):\n",
    "    \"\"\" Saves array of answers \"\"\"\n",
    "    with open(fname, \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in array]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "View frequency model@1: recall=0.44\tprecision=0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danila/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View frequency model@5: recall=0.82\tprecision=0.21\n",
      "Purchases frequency model@1: recall=0.69\tprecision=0.80\n",
      "Purchases frequency model@5: recall=0.93\tprecision=0.25\n",
      "()\n",
      "Test\n",
      "View frequency model@1: recall=0.42\tprecision=0.48\n",
      "View frequency model@5: recall=0.80\tprecision=0.20\n",
      "Purchases frequency model@1: recall=0.46\tprecision=0.53\n",
      "Purchases frequency model@5: recall=0.82\tprecision=0.21\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "data_train_clear = data_train.dropna(axis=0, how=\"any\")\n",
    "models = [\n",
    "    (\"View frequency model\", lambda views, k: build_recommendations(views, view_frequencies, k)),\n",
    "    (\"Purchases frequency model\", lambda views, k: build_recommendations(views, buy_frequencies, k))\n",
    "]\n",
    "datas = [\n",
    "    (\"Train\", data_train_clear),\n",
    "    (\"Test\", data_test)\n",
    "]\n",
    "ks = [1,5]\n",
    "for data_name, data in datas:\n",
    "    print(data_name)\n",
    "    for model_name, model in models:\n",
    "        results = []\n",
    "        for k in ks:\n",
    "            average_recall, average_precision = estimate_model(data, model, k)\n",
    "            results.append(np.round(average_recall, 2))\n",
    "            results.append(np.round(average_precision, 2))\n",
    "            print(\"%s@%i: recall=%.2f\\tprecision=%.2f\" % (model_name, k, average_recall, average_precision))\n",
    "#         fileName = (data_name + \"_\" + model_name + \".txt\")\n",
    "#         save_answer_array(\"DataAnalisysMipt\\\\Results\\\\\" + fileName, results)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
